\section{Lessons and Challenges}


\subsection{Zero-Configuration Autograders}

Both  surveys of autograders ask why existing autograders aren't reused more.
We believe one reason is the configuration required for teachers to deploy them and
students to submit work to them.  Since we
faced and surmounted this problem in deploying our ``autograders as a
service'' with OpenEdX, we can make them easy for others to use.

\tbd{discuss in-progress tools and refactoring that will allow creating new assignments
  that use existing grading engines, without worrying about autograders
  at all}

We already have several instructors running SPOCs based on our
materials~\cite{moocs-spocs-TR} using OpenEdX.  They not only use our
autograders but can create new assignments that take advantage of them.

\tbd{or create another adapter than XQueue - refer to figure - we're now
doing it for Octobear}

\subsection{Challenge: Tuning Rubrics}

tuning rubrics. Use campus course to debug. Use CI to
verify we haven't broken stuff.

test suite quality: THis si a general problem in SWE. Example: if multiple tests are effectively redundant, student scoring is positively distorted if all pass and negatively distorted if all fail.


\subsection{Challenge: Avoiding ``Autograder-Driven Development''}

\subsection{Challenge: Combining With Manual Grading}



\subsection{Challenge: Stability}

By and large edX works.  Good separation
of concerns between LMS and autograder authors.




